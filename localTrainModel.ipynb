{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:59:29.965570Z",
     "start_time": "2025-04-18T18:59:24.866165Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error,root_mean_squared_error\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04f05544a96f945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:17:28.235984Z",
     "start_time": "2025-03-31T13:17:28.161399Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('preprocessed_data.csv')\n",
    "# data[\"datetime\"]= data[\"UnixTime\"].apply(lambda x: datetime.fromtimestamp(x))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d4dc9fd4098e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T20:01:10.559453Z",
     "start_time": "2025-04-18T20:01:08.000577Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sorted_data_final.csv\")\n",
    "df = df.sort_values(by='UnixTime')\n",
    "\n",
    "#df.drop(columns=\"DateKey\", inplace= True)\n",
    "df['SinHour'] = np.sin(2 * np.pi * df['Hour'] / 24)\n",
    "df['CosHour'] = np.cos(2 * np.pi * df['Hour'] / 24)\n",
    "df.drop(columns=[\"Month\",\"Day\", \"Hour\" ,\"UnixTime\"])\n",
    "\n",
    "use_multivariate = True\n",
    "seq_length = 48\n",
    "target_column_name = \"Irradiance\"\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_split_idx = int(len(df) * train_ratio)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(df.iloc[:train_split_idx + seq_length])\n",
    "scaled_test = scaler.transform(df.iloc[train_split_idx + seq_length:])\n",
    "df_scaled = pd.DataFrame(np.vstack([scaled_train, scaled_test]), columns=df.columns)\n",
    "\n",
    "\n",
    "def create_sequences(data, target_column, seq_length=12, univariate=False):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        if univariate:\n",
    "            X.append(data[i:i + seq_length, target_column].reshape(-1, 1))\n",
    "        else:\n",
    "            X.append(data[i:i + seq_length, :])\n",
    "        y.append(data[i + seq_length, target_column])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "target_column = df_scaled.columns.get_loc(target_column_name)\n",
    "X, y = create_sequences(df_scaled.values, target_column, seq_length, univariate=not use_multivariate)\n",
    "\n",
    "X_train, X_test = X[:train_split_idx], X[train_split_idx:]\n",
    "y_train, y_test = y[:train_split_idx], y[train_split_idx:]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "# --- GRU MODEL ---\n",
    "# model = Sequential([\n",
    "#     GRU(128, return_sequences=True, input_shape=(seq_length, X_train.shape[2]), kernel_regularizer=l2(0.0005)),\n",
    "#     GRU(128, return_sequences=True, kernel_regularizer=l2(0.0005)),\n",
    "#     #GRU(64, return_sequences=False, kernel_regularizer=l2(0.0005)),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(1)\n",
    "# ])\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(256, return_sequences=True, input_shape=(seq_length, X_train.shape[2]), kernel_regularizer=l2(0.0001)),\n",
    "    LSTM(128, return_sequences=True, kernel_regularizer=l2(0.0001)),\n",
    "    LSTM(64, return_sequences=False, kernel_regularizer=l2(0.0001)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.005), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32722c22c0d9f9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T20:28:14.328433Z",
     "start_time": "2025-04-18T20:01:10.588299Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_gru_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',       \n",
    "    factor=0.5,               \n",
    "    patience=7,             \n",
    "    min_lr=1e-5,           \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0e12d081cdd1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T20:37:45.621637Z",
     "start_time": "2025-04-18T20:37:42.426295Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "def inverse_transform_target(scaled_target, scaler, n_features, target_index):\n",
    "    zero_filled = np.zeros((len(scaled_target), 13))\n",
    "    zero_filled[:, target_index] = scaled_target.flatten()\n",
    "    return scaler.inverse_transform(zero_filled)[:, target_index]\n",
    "\n",
    "y_test_actual = inverse_transform_target(y_test, scaler, df.shape[1], target_column)\n",
    "y_pred_actual = inverse_transform_target(y_pred, scaler, df.shape[1], target_column)\n",
    "\n",
    "mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "r2 = r2_score(y_test_actual, y_pred_actual)\n",
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "mape = mean_absolute_percentage_error(y_test_actual, y_pred_actual)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R2  {r2}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MAPE: {mape}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this visualisation was done by chat gpt weekly graphs wanted to make sure that the model is behaving correctly\n",
    "# and I did not see small time frames very well if I did it on whole test set\n",
    "df['Timestamp'] = pd.to_datetime(df['UnixTime'], unit='s')\n",
    "df['ISO_Week'] = df['Timestamp'].dt.isocalendar().week\n",
    "\n",
    "# Extract test index range\n",
    "test_start_idx = train_split_idx + seq_length\n",
    "test_end_idx = test_start_idx + len(y_test)\n",
    "\n",
    "# Get timestamps and weeks for test set\n",
    "timestamps = df.iloc[test_start_idx:test_end_idx]['Timestamp'].values\n",
    "iso_weeks = df.iloc[test_start_idx:test_end_idx]['ISO_Week'].values\n",
    "\n",
    "# Build aligned predictions DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Timestamp': timestamps,\n",
    "    'Week': iso_weeks,\n",
    "    'Predicted Irradiance': y_pred_actual,\n",
    "    'Actual Irradiance': y_test_actual\n",
    "})\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(\"weekly_plots\", exist_ok=True)\n",
    "\n",
    "# Plot each week in the test set\n",
    "for week in sorted(predictions_df['Week'].unique()):\n",
    "    weekly_data = predictions_df[predictions_df['Week'] == week]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(weekly_data['Timestamp'], weekly_data['Actual Irradiance'], label=\"Skutočnosť\", color='blue', alpha=0.6)\n",
    "    plt.plot(weekly_data['Timestamp'], weekly_data['Predicted Irradiance'], label=\"Predikcia\", color='red', alpha=0.6)\n",
    "    plt.xlabel(\"Čas\")\n",
    "    plt.ylabel(\"Slnečné žiarenie\")\n",
    "    plt.title(f\"Tyždeň {week} - Predikcia vs Skutočnosť\")\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"weekly_plots/week_{week}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test_actual, y_pred_actual, alpha=0.5, color='green', edgecolors='k')\n",
    "plt.plot([min(y_test_actual), max(y_test_actual)],\n",
    "         [min(y_test_actual), max(y_test_actual)],\n",
    "         color='black', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Skutočná hodnota (Irradiancia)\")\n",
    "plt.ylabel(\"Predikovaná hodnota (Irradiancia)\")\n",
    "plt.title(f\"R² Rozptylový graf\\nR² skóre: {r2:.3f}\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Ulož graf\n",
    "plt.savefig(\"r2_scatter_plot.png\", dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef6489b445eb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
