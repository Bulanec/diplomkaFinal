{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7421f9a7-40d4-4ba9-af76-53fac64b51b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sin, cos, lit\n",
    "import math\n",
    "\n",
    "# again need to connect to manipulate with tables in databricks\n",
    "spark = SparkSession.getActiveSession()\n",
    "\n",
    "silver_schema = \"model_workspace.silver\"\n",
    "gold_schema = \"model_workspace.gold\"\n",
    "\n",
    "# get silver tables by name where I added instead of month for bronze _features\n",
    "silver_tables = spark.sql(f\"SHOW TABLES IN {silver_schema}\") \\\n",
    "    .filter(\"tableName LIKE '%_features'\") \\\n",
    "    .select(\"tableName\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# get only columns with good corelation and keep some for logging\n",
    "selected_columns = [\n",
    "    \"Irradiance\", \"BodyTemperature\", \"RelativeHumidity\",\n",
    "      \"Pressure\",\n",
    "    \"SunZenith\", \"Month\", \"Day\", \n",
    "    \"DayofTheYear\", \"Hour\", \"UnixTime\", \"DayLength\"\n",
    "]\n",
    "final_columns = [\n",
    "    \"Irradiance\", \"BodyTemperature\", \n",
    "    \"RelativeHumidity\", \"Pressure\",\n",
    "    \"SunZenith\", \"DayOfTheYear\", \"Hour\", \n",
    "    \"SinHour\", \"CosHour\", \"UnixTime\", \"DayLength\"\n",
    "]\n",
    "\n",
    "\n",
    "#same as in silver first we need to check if table is in gold schema and then save it if not\n",
    "\n",
    "for table_name in silver_tables:\n",
    "    silver_table = f\"{silver_schema}.{table_name}\"\n",
    "    gold_table = f\"{gold_schema}.{table_name.replace('_features', '_gold')}\"\n",
    "\n",
    "    if spark._jsparkSession.catalog().tableExists(gold_table):\n",
    "        print(f\"skipping existing : {gold_table}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"procesing: {silver_table} to {gold_table}\")\n",
    "\n",
    "    try:\n",
    "        df = spark.read.table(silver_table)\n",
    "        df = df.select(*selected_columns)\n",
    "\n",
    "        \n",
    "        df = df.withColumn(\"SinHour\", sin(2 * math.pi * col(\"Hour\") / lit(24)))\n",
    "        df = df.withColumn(\"CosHour\", cos(2 * math.pi * col(\"Hour\") / lit(24)))\n",
    "\n",
    "        df = df.drop(\"Hour\")\n",
    "\n",
    "        # if for some reason tables were not sorted it could cause problems during training\n",
    "        df = df.orderBy(\"UnixTime\")\n",
    "        df = df.select(*final_columns)\n",
    "        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(gold_table)\n",
    "        print(f\" saved to gold schema:  {gold_table}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"err {table_name}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
